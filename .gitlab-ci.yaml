stages:
  - build
  - sync-e2e-benchmark
  - collector
  - cleanup


include:
  - project: hive/haf
    ref: 319551c0bd84a9490ba5000d18efbb335f7559d6 # mine branch
    file: /scripts/ci-helpers/prepare_data_image_job.yml


variables:
  # HIVEMIND
  RUNNER_HIVEMIND_SERVER_HTTP_PORT: 8080
  # HAF
  HAF_POSTGRES_URL: postgresql://haf_app_admin@haf-instance:5432/haf_block_log
  HAF_ADMIN_POSTGRES_URL: postgresql://haf_admin@haf-instance:5432/haf_block_log
  # FF:
  FF_NETWORK_PER_BUILD: 1
  # GIT:
  GIT_DEPTH: 1
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: recursive
  CI_DEBUG_SERVICES: "true"
  DATA_CACHE_MAINNET: /cache/replay_data_hivemind_${CI_PIPELINE_ID}
  BLOCK_LOG_SOURCE_DIR_5M: /blockchain/block_log_5m
  DATA_CACHE_MIRRORNET: /cache/replay_data_hivemind_${CI_PIPELINE_ID}
  BLOCK_LOG_SOURCE_DIR_MIRRORNET_5M: /blockchain/block_log_5m_mirrornet

workflow:
  # do not create pipeline twice when merge requests is open on current branch
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_MERGE_REQUEST_ID'
    - if: '$CI_OPEN_MERGE_REQUESTS'
      when: never
    - when: always


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| ANCHORS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.shared_tags:
  tags: &shared_tags
    - public-runner-docker
    - hived-for-tests


.start-timer: &start-timer
  - ./scripts/ci/timer.sh start


.check-timer: &check-timer
  - ./scripts/ci/timer.sh check

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| ANCHORS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| BASH SCRIPTS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.bridge_api_smoketest-script: &bridge_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_patterns/ \
        api_smoketest_bridge.xml \
        $RUNNER_PYTEST_WORKERS


.bridge_api_smoketest_negative-script: &bridge_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_negative/ \
        api_smoketest_bridge_negative.xml \
        $RUNNER_PYTEST_WORKERS


.condenser_api_smoketest-script: &condenser_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_patterns/ \
        api_smoketest_condenser_api.xml \
        $RUNNER_PYTEST_WORKERS


.condenser_api_smoketest_negative-script: &condenser_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_negative/ \
        api_smoketest_condenser_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.database_api_smoketest-script: &database_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_patterns/ \
        api_smoketest_database_api.xml \
        $RUNNER_PYTEST_WORKERS


.database_api_smoketest_negative-script: &database_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_negative/ \
        api_smoketest_database_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.follow_api_smoketest-script: &follow_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_patterns/ \
        api_smoketest_follow_api.xml \
        $RUNNER_PYTEST_WORKERS


.follow_api_smoketest_negative-script: &follow_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_negative/ \
        api_smoketest_follow_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.tags_api_smoketest-script: &tags_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_negative/ \
        api_smoketest_tags_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.tags_api_smoketest_negative-script: &tags_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_patterns/ \
        api_smoketest_tags_api.xml \
        $RUNNER_PYTEST_WORKERS


.mock_tests-script: &mock_tests-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        mock_tests/ \
        api_smoketest_mock_tests.xml \
        $RUNNER_PYTEST_WORKERS


.hive_api_smoketest-script: &hive_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        hive_api_patterns/ \
        api_smoketest_hive_api.xml \
        $RUNNER_PYTEST_WORKERS


.api-benchmark-script: &api-benchmark-script
  - |
    ./scripts/ci/start-api-benchmarks.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        $RUNNER_BENCHMARK_ITERATIONS \
        $RUNNER_PYTEST_WORKERS

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| BASH SCRIPTS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| JOBS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

prepare_haf_image_mirrornet:
  stage: build
  extends: .prepare_haf_image
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    REGISTRY_USER: "$HAF_IMG_BUILDER_USER"
    REGISTRY_PASS: "$HAF_IMG_BUILDER_PASSWORD"
    HIVE_NETWORK_TYPE: mirrornet
  tags: *shared_tags


prepare_haf_data_mirrornet:
  extends: .prepare_haf_data_5m
  needs:
    - job: prepare_haf_image_mirrornet
      artifacts: true
  stage: build
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    BLOCK_LOG_SOURCE_DIR: $BLOCK_LOG_SOURCE_DIR_MIRRORNET_5M
    CONFIG_INI_SOURCE: "$CI_PROJECT_DIR/haf/hive/docker/config_mirrornet_5M.ini"
    FAKETIME_TIMESTAMP: "2016-09-15T19:47:21"
  tags:
    - hive-builder-4


cleanup_haf_cache_manual:
  extends: .cleanup_cache_manual
  stage: cleanup
  variables:
    CLEANUP_PATH_PATTERN: "/cache/replay_data_hivemind_*"
  resource_group: ${CI_COMMIT_SHA}
  tags:
    - hive-builder-4


hivemind_live_sync:
  image: $CI_REGISTRY_IMAGE/ci_base_image:3.8
  stage: sync-e2e-benchmark
  needs:
    - job: prepare_haf_data_mirrornet
      artifacts: true
  when: on_success
  services:
    - name: $HAF_IMAGE_NAME
      alias: haf-instance
      variables:
        PG_ACCESS: "
         host    haf_block_log    haf_app_admin    0.0.0.0/0    trust\n
         host    haf_block_log    haf_admin        0.0.0.0/0    trust\n
         "
        DATADIR: $DATA_CACHE_MIRRORNET/datadir
        SHM_DIR: $DATA_CACHE_MIRRORNET/shm_dir
        LOG_FILE: $CI_JOB_NAME.log
      command: ["--replay-blockchain"]
  variables:
    RUNNER_HIVEMIND_SYNC_MAX_BLOCK: 5000024
    HIVED_UID: $HIVED_UID
  before_script:
    - scripts/ci/fix_ci_tag.sh
    - python3 -V
    - pip3 -V
    - python3 -m venv venv/
    - . venv/bin/activate
    - pip install --upgrade pip setuptools wheel
    - pip install --no-cache-dir .[tests] 2>&1 | tee pip_install.log
    - pip list
    - env
  script:
    - echo "HAF image name $HAF_IMAGE_NAME"
    - ./scripts/ci/wait-for-postgres.sh $HAF_ADMIN_POSTGRES_URL
    - psql $HAF_ADMIN_POSTGRES_URL -c 'SELECT max(num) FROM hive.blocks;'
    - sleep 60
    - psql $HAF_ADMIN_POSTGRES_URL -c 'SELECT max(num) FROM hive.blocks;'
  artifacts:
    when: always
    expire_in: 7 days
    reports:
      junit: "*.xml"
      dotenv: variables.env
    paths:
      - pip_install.log
  tags:
    - hive-builder-4
