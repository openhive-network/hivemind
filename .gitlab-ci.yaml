stages:
  - build
  - sync
  - test
  - benchmark
  - collector


include:
  - project: 'hive/haf'
    ref: develop
    file: '/scripts/ci-helpers/prepare_data_image_job.yml'


variables:
  HAF_CONTAINER_NAME: haf_instance
  # HIVEMIND
  RUNNER_HIVEMIND_SERVER_HTTP_PORT: 8080
  # HAF
  HAF_POSTGRES_URL: postgresql://haf_app_admin@haf-instance:5432/haf_block_log
  HAF_ADMIN_POSTGRES_URL: postgresql://haf_admin@haf-instance:5432/haf_block_log
  # FF:
  FF_NETWORK_PER_BUILD: 1
  # GIT:
  GIT_DEPTH: 1
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: recursive


workflow:
  # do not create pipeline twice when merge requests is open
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_MERGE_REQUEST_ID'
    - if: '$CI_OPEN_MERGE_REQUESTS'
      when: never
    - when: always


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| SETUPS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.setup_with_dind:
  image: $CI_REGISTRY_IMAGE/ci_base_image_with_docker:3.8
  services:
    - docker:20.10.10-dind
  variables:
    DOCKER_BUILDKIT: 1
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: "/certs"

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| SETUPS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| HELPERS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.start-timer: &start-timer
  - ./scripts/ci/timer.sh start


.check-timer: &check-timer
  - ./scripts/ci/timer.sh check

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| HELPERS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| ANCHORS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
.shared_tags:
  tags: &shared_tags
    - public-runner-docker
    - hived-for-tests

.bridge_api_smoketest-script: &bridge_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_patterns/ \
        api_smoketest_bridge.xml \
        $RUNNER_PYTEST_WORKERS


.bridge_api_smoketest_negative-script: &bridge_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_negative/ \
        api_smoketest_bridge_negative.xml \
        $RUNNER_PYTEST_WORKERS


.condenser_api_smoketest-script: &condenser_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_patterns/ \
        api_smoketest_condenser_api.xml \
        $RUNNER_PYTEST_WORKERS


.condenser_api_smoketest_negative-script: &condenser_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_negative/ \
        api_smoketest_condenser_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.database_api_smoketest-script: &database_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_patterns/ \
        api_smoketest_database_api.xml \
        $RUNNER_PYTEST_WORKERS


.database_api_smoketest_negative-script: &database_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_negative/ \
        api_smoketest_database_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.follow_api_smoketest-script: &follow_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_patterns/ \
        api_smoketest_follow_api.xml \
        $RUNNER_PYTEST_WORKERS


.follow_api_smoketest_negative-script: &follow_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_negative/ \
        api_smoketest_follow_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.tags_api_smoketest-script: &tags_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_negative/ \
        api_smoketest_tags_api_negative.xml \
        $RUNNER_PYTEST_WORKERS


.tags_api_smoketest_negative-script: &tags_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_patterns/ \
        api_smoketest_tags_api.xml \
        $RUNNER_PYTEST_WORKERS


.mock_tests-script: &mock_tests-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        mock_tests/ \
        api_smoketest_mock_tests.xml \
        $RUNNER_PYTEST_WORKERS


.hive_api_smoketest-script: &hive_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        hive_api_patterns/ \
        api_smoketest_hive_api.xml \
        $RUNNER_PYTEST_WORKERS


.api-benchmark-script: &api-benchmark-script
  - |
    ./scripts/ci/start-api-benchmarks.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        $RUNNER_BENCHMARK_ITERATIONS \
        $RUNNER_PYTEST_WORKERS

.prepare:
  before_script: &prepare
    - apk update && apk add bash git ca-certificates curl build-base python3-dev postgresql-client
    - scripts/ci/fix_ci_tag.sh
    - pip install --upgrade pip setuptools wheel
    - python3 -V
    - pip3 -V
    - python3 -m venv venv/
    - . venv/bin/activate
    - pip install --no-cache-dir ."[dev]" 2>&1 | tee pip_install.log
    - pip list

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| ANCHORS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| JOBS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

prepare_haf_image:
  stage: build
  extends: .prepare_haf_data_5m_image
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: always
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always
    - if: '$CI_COMMIT_BRANCH == "develop"'
      when: always
    - when: manual
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    REGISTRY_USER: "$HAF_IMG_BUILDER_USER"
    REGISTRY_PASS: $HAF_IMG_BUILDER_PASSWORD
  tags:
    - public-runner-docker
    - hived-for-tests


sync_hivemind:
  stage: sync
  image: $CI_REGISTRY_IMAGE/ci_base_image_with_docker:3.8
  needs: [ 'prepare_haf_image' ]
  rules:
    - when: on_success
  services:
    - name: docker:20.10.10-dind
      alias: dind
  variables:
    DOCKER_HOST: tcp://dind:2376
    DOCKER_BUILDKIT: 1
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: "/certs"
    RUNNER_HIVEMIND_SYNC_MAX_BLOCK: 5000024
  before_script: *prepare
  script:
    - echo "HAF image name $HAF_IMAGE_NAME"
    - docker info
    - docker context list
    - docker run -d --name $HAF_CONTAINER_NAME $HAF_IMAGE_NAME
    - ./scripts/ci/wait-for-postgres.sh $HAF_CONTAINER_NAME
    - ./scripts/ci/add-mocks-to-db.sh
    - psql "${HAF_ADMIN_POSTGRES_URL}" -c 'CREATE EXTENSION IF NOT EXISTS intarray;'
    - ./scripts/ci/hive-sync.sh
    - ./scripts/ci/collect-db-stats.sh
    - docker commit $HAF_CONTAINER_NAME synced_image
    - docker images
    - docker save -o image.tar synced_image
  after_script:
    - echo "SERVER_NAME=$CI_RUNNER_DESCRIPTION" >> variables.env
  artifacts:
    expire_in: 7 days
    reports:
      dotenv: variables.env
    paths:
      - image.tar
      - pip_install.log
      - hivemind-sync.log
      - pg-stats
      - tests/api_tests/hivemind/tavern/**/*.out.json
  tags: *shared_tags


run_e2e_tests:
  stage: test
  extends: .setup_with_dind
  needs: [ 'prepare_haf_image', 'sync_hivemind' ]
  before_script: *prepare
  script:
    - docker load -i image.tar
    - docker images
    - docker run -d --name $HAF_CONTAINER_NAME synced_image
    - ./scripts/ci/wait-for-postgres.sh $HAF_CONTAINER_NAME
    - psql "${HAF_ADMIN_POSTGRES_URL}" -c 'SELECT MAX(num) FROM hive.blocks;'
    - ./scripts/ci/hive-server.sh start
    - *bridge_api_smoketest-script
    - *bridge_api_smoketest_negative-script
    - *condenser_api_smoketest-script
    - *condenser_api_smoketest_negative-script
    - *database_api_smoketest-script
    - *database_api_smoketest_negative-script
    - *follow_api_smoketest-script
    - *follow_api_smoketest_negative-script
    - *tags_api_smoketest-script
    - *tags_api_smoketest_negative-script
    - *mock_tests-script
    - *hive_api_smoketest-script
    - ./scripts/ci/hive-server.sh stop
  after_script:
    mv hivemind-server.log hivemind-server.smoke-tests.log
    mv request_process_times.log request_process_times.smoke-tests.log
  artifacts:
    paths:
      - pip_install.log
      - hivemind-server.smoke-tests.log
      - request_process_times.smoke-tests.log
  tags: *shared_tags


run_benchmark:
  stage: benchmark
  extends: .setup_with_dind
  needs: [ 'prepare_haf_image', 'sync_hivemind', 'run_e2e_tests' ]
  before_script: *prepare
  script:
    - docker load -i image.tar
    - docker images
    - docker run -d --name $HAF_CONTAINER_NAME synced_image
    - ./scripts/ci/wait-for-postgres.sh $HAF_CONTAINER_NAME
    - psql "${HAF_ADMIN_POSTGRES_URL}" -c 'SELECT MAX(num) FROM hive.blocks;'
    - ./scripts/ci/hive-server.sh start
    - *api-benchmark-script
    - ./scripts/ci/hive-server.sh stop
  artifacts:
    paths:
      - pip_install.log
      - hivemind-server.log
      - request_process_times.log
      - tavern_benchmarks_report.html
  tags: *shared_tags


collect_artifacts:
  stage: collector
  needs: [ 'sync_hivemind', 'run_e2e_tests', 'run_benchmark' ]
  script:
    - ls -al
    - cat hivemind-server.log
  after_script:
    - echo "ARTIFACTS_JOB_ID=$CI_JOB_ID" >> variables.env
    - echo "APP_VERSION=$(git describe --tags)" >> variables.env
  artifacts:
    reports:
      dotenv: artifacts/variables.env
    paths:
      - hivemind-sync.log
      - hivemind-server.log
      - request_process_times.log
  tags: *shared_tags


#Trigger benchmark-results-collector:
#  stage: collector
#  needs: [ 'collect_artifacts' ]
#  rules:
#    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
#      when: never
#    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
#      when: on_success
#    - if: '$CI_COMMIT_BRANCH == "develop"'
#      when: on_success
#    - when: manual
#  variables:
#    ARTIFACTS_URL: https://gitlab.syncad.com/api/v4/projects/$CI_PROJECT_ID/jobs/$ARTIFACTS_JOB_ID/artifacts
#    PRIVATE_TOKEN: $READ_ARTIFACT_ACCESS_TOKEN
#    #description:
#    SOURCE: hivemind
#    JOB_ID: $ARTIFACTS_JOB_ID
#    DESC: "hivemind CI"
#    EXEC_ENV_DESC: branch=$CI_COMMIT_REF_SLUG
#    SERVER_NAME: $SERVER_NAME
#    APP_VERSION: $APP_VERSION
#    TESTSUITE_VERSION: commit_short_sha=$CI_COMMIT_SHORT_SHA
#  trigger:
#    project: hive/benchmark-results-collector
#    branch: master
#    strategy: depend

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| JOBS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
