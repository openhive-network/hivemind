stages:
  - build
  - sync-e2e-benchmark
  - publish
  - collector
  - cleanup

variables:
  # HIVEMIND
  RUNNER_HIVEMIND_SERVER_HTTP_PORT: 8080
  RUNNER_HIVEMIND_BENCHMARK_SERVER_HOSTNAME: hivemind-benchmark
  RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME: hivemind-smoketest
  # HAF
  HAF_POSTGRES_URL: postgresql://haf_app_admin@haf-instance:5432/haf_block_log
  HAF_ADMIN_POSTGRES_URL: postgresql://haf_admin@haf-instance:5432/haf_block_log
  # FF:
  FF_NETWORK_PER_BUILD: 1
  # GIT:
  GIT_DEPTH: 1
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: recursive
  CI_DEBUG_SERVICES: "true"
  DATA_CACHE_HAF_TEMPLATE: /cache/replay_data_hivemind_haf
  DATA_CACHE_HAF: "/cache/replay_data_hivemind_haf_${CI_PIPELINE_ID}"
  BLOCK_LOG_SOURCE_DIR_5M: /blockchain/block_log_5m

include:
  - project: hive/haf
    ref: 94183788111c2f6f650859ad11bebbf867aa5010 # develop
    file: /scripts/ci-helpers/prepare_data_image_job.yml

workflow:
  # do not create pipeline twice when merge requests is open on current branch
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_MERGE_REQUEST_ID'
    - if: '$CI_OPEN_MERGE_REQUESTS'
      when: never
    - when: always

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| ANCHORS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.shared_tags:
  tags: &shared_tags
    - public-runner-docker
    - hived-for-tests

.start-timer: &start-timer
  - ./scripts/ci/timer.sh start

.check-timer: &check-timer
  - ./scripts/ci/timer.sh check

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| ANCHORS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| BASH SCRIPTS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.instance-build-script: &instance-build-script
  - |
    ./scripts/ci-helpers/build_instance.sh \
      "$CI_COMMIT_SHA" \
      "$CI_PROJECT_DIR" \
      "$CI_REGISTRY_IMAGE" \
      --dot-env-filename=hivemind_image.env \
      --dot-env-var-name=HIVEMIND_IMAGE
    docker images
    docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"
    source hivemind_image.env
    docker push "$HIVEMIND_IMAGE"  

.bridge_api_smoketest-script: &bridge_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_patterns/ \
        api_smoketest_bridge.xml \
        $RUNNER_PYTEST_WORKERS

.bridge_api_smoketest_negative-script: &bridge_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_negative/ \
        api_smoketest_bridge_negative.xml \
        $RUNNER_PYTEST_WORKERS

.condenser_api_smoketest-script: &condenser_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_patterns/ \
        api_smoketest_condenser_api.xml \
        $RUNNER_PYTEST_WORKERS

.condenser_api_smoketest_negative-script: &condenser_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_negative/ \
        api_smoketest_condenser_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.database_api_smoketest-script: &database_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_patterns/ \
        api_smoketest_database_api.xml \
        $RUNNER_PYTEST_WORKERS

.database_api_smoketest_negative-script: &database_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_negative/ \
        api_smoketest_database_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.follow_api_smoketest-script: &follow_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_patterns/ \
        api_smoketest_follow_api.xml \
        $RUNNER_PYTEST_WORKERS

.follow_api_smoketest_negative-script: &follow_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_negative/ \
        api_smoketest_follow_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.tags_api_smoketest-script: &tags_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_negative/ \
        api_smoketest_tags_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.tags_api_smoketest_negative-script: &tags_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_patterns/ \
        api_smoketest_tags_api.xml \
        $RUNNER_PYTEST_WORKERS

.mock_tests-script: &mock_tests-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        mock_tests/ \
        api_smoketest_mock_tests.xml \
        $RUNNER_PYTEST_WORKERS

.hive_api_smoketest-script: &hive_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        $RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        hive_api_patterns/ \
        api_smoketest_hive_api.xml \
        $RUNNER_PYTEST_WORKERS

.api-benchmark-script: &api-benchmark-script
  - |
    ./scripts/ci/start-api-benchmarks.sh \
        $RUNNER_HIVEMIND_BENCHMARK_SERVER_HOSTNAME \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        $RUNNER_BENCHMARK_ITERATIONS \
        $RUNNER_PYTEST_WORKERS 

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| BASH SCRIPTS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| JOBS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

prepare_haf_image:
  stage: build
  extends: .prepare_haf_image
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    REGISTRY_USER: "$HAF_IMG_BUILDER_USER"
    REGISTRY_PASS: "$HAF_IMG_BUILDER_PASSWORD"
  before_script:
    - git config --global --add safe.directory $CI_PROJECT_DIR/haf
  tags: *shared_tags

prepare_haf_data:
  extends: .prepare_haf_data_5m
  needs:
    - job: prepare_haf_image
      artifacts: true
  stage: build
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    BLOCK_LOG_SOURCE_DIR: $BLOCK_LOG_SOURCE_DIR_5M
    CONFIG_INI_SOURCE: "$CI_PROJECT_DIR/haf/docker/config_5M.ini"
  tags:
    - hive-builder-4

prepare_hivemind_image:
  stage: build
  extends: .docker_image_builder_job_template
  before_script:
    - git config --global --add safe.directory $CI_PROJECT_DIR
  script:
    - *instance-build-script
  artifacts:
    when: always
    expire_in: 7 days
    reports:
      dotenv: hivemind_image.env
    paths:
      - hivemind_image.env
  tags: *shared_tags

cleanup_haf_cache_manual:
  extends: .cleanup_cache_manual
  stage: cleanup
  variables:
    CLEANUP_PATH_PATTERN: "/cache/replay_data_hivemind_*"
  resource_group: ${CI_COMMIT_SHA}
  tags:
    - hive-builder-4

sync_e2e_benchmark:
  image: $CI_REGISTRY_IMAGE/ci_base_image:3.8
  stage: sync-e2e-benchmark
  needs:
    - job: prepare_haf_data
      artifacts: true
    - job: prepare_hivemind_image
      artifacts: true
  when: on_success
  services:
    - name: $HAF_IMAGE_NAME
      alias: haf-instance
      variables:
        PG_ACCESS: "
         host    haf_block_log    haf_app_admin    all    trust\n
         host    haf_block_log    haf_admin        all    trust\n
         "
        DATADIR: $DATA_CACHE_HAF/datadir
        SHM_DIR: $DATA_CACHE_HAF/shm_dir
        LOG_FILE: $CI_JOB_NAME.log
      command: ["--replay-blockchain", "--stop-replay-at-block=5000000"]
    - name: $HIVEMIND_IMAGE
      alias: hivemind-sync # cannot be a variable
      entrypoint:
        - bash
        - -c
        - |
          cat /etc/hosts && \
          sleep 20s && \
          cd ${WORKING_DIR}/app && \
          ci/wait-for-postgres.sh ${HAF_ADMIN_POSTGRES_URL} && \
          cd ${WORKING_DIR} && \
          cat ${WORKING_DIR}/.hivemind-venv/lib/python3.8/site-packages/hive/_version.py > version.log && \
          /home/hivemind/docker_entrypoint.sh setup \
            --database-admin-url="${HAF_ADMIN_POSTGRES_URL}" \
            --add-mocks=${ADD_MOCKS} && \
          ${WORKING_DIR}/docker_entrypoint.sh sync \
            --log-mask-sensitive-data \
            --pid-file hive_sync.pid \
            --test-max-block="${RUNNER_HIVEMIND_SYNC_MAX_BLOCK}" \
            --test-profile=False \
            --prometheus-port 11011 \
            --database-url="${HAF_POSTGRES_URL}" \
            --community-start-block 4998000 && \
          ${WORKING_DIR}/app/ci/collect-db-stats.sh && \
          python -m http.server ${RUNNER_HIVEMIND_SERVER_HTTP_PORT}
      variables:
        WORKING_DIR: /home/hivemind
        LOG_PATH: $WORKING_DIR/hivemind-sync.log
        ADD_MOCKS: "true"
    - name: $HIVEMIND_IMAGE
      alias: hivemind-smoketest # cannot be a variable
      entrypoint:
        - bash
        - -c
        - |
          (python -m http.server --directory ${WORKING_DIR} $LOG_SERVER_PORT &) && \
          cat /etc/hosts && \
          wget --header "PRIVATE-TOKEN: $AWAIT_SERVICE_ACCESS_TOKEN" "$AWAIT_PACKAGE_URL" -O ${WORKING_DIR}/await && \
          chmod +x ${WORKING_DIR}/await && \
          ${WORKING_DIR}/await -t 5m postgres://haf_admin@haf-instance:5432/haf_block_log#schemas=hivemind_app -- echo "Database found" && \
          ${WORKING_DIR}/await -t 1h ${RUNNER_HIVEMIND_SYNC_URL} -- echo "Hivemind sync finished" && \
          ${WORKING_DIR}/docker_entrypoint.sh server \
            --log-request-times \
            --log-request-times-path=${WORKING_DIR}/request_process_times_smoketests.log \
            --log-mask-sensitive-data \
            --http-server-port=${RUNNER_HIVEMIND_SERVER_HTTP_PORT} \
            --database-url="${HAF_POSTGRES_URL}"
      variables:
        WORKING_DIR: /home/hivemind
        LOG_PATH: /home/hivemind/hivemind-server.log
    - name: $HIVEMIND_IMAGE
      alias: hivemind-benchmark # cannot be a variable
      entrypoint:
        - bash
        - -c
        - |
          (python -m http.server --directory ${WORKING_DIR} $LOG_SERVER_PORT &) && \
          cat /etc/hosts && \
          wget --header "PRIVATE-TOKEN: $AWAIT_SERVICE_ACCESS_TOKEN" "$AWAIT_PACKAGE_URL" -O ${WORKING_DIR}/await && \
          chmod +x ${WORKING_DIR}/await && \
          ${WORKING_DIR}/await -t 5m postgres://haf_admin@haf-instance:5432/haf_block_log#schemas=hivemind_app -- echo "Database found" && \
          ${WORKING_DIR}/await -t 1h ${RUNNER_HIVEMIND_SYNC_URL} -- echo "Hivemind sync finished" && \
          ${WORKING_DIR}/docker_entrypoint.sh server \
            --log-request-times \
            --log-request-times-path=${WORKING_DIR}/request_process_times.log \
            --log-mask-sensitive-data \
            --http-server-port=${RUNNER_HIVEMIND_SERVER_HTTP_PORT} \
            --database-url="${HAF_POSTGRES_URL}"
      variables:
        WORKING_DIR: /home/hivemind
        LOG_PATH: /home/hivemind/hivemind-benchmark-server.log
  variables:
    RUNNER_HIVEMIND_SYNC_MAX_BLOCK: 5000024
    HIVED_UID: $HIVED_UID
    RUNNER_HIVEMIND_SYNC_HOSTNAME: hivemind-sync
    RUNNER_HIVEMIND_SYNC_URL: http://$RUNNER_HIVEMIND_SYNC_HOSTNAME:$RUNNER_HIVEMIND_SERVER_HTTP_PORT
    RUNNER_HIVEMIND_BENCHMARK_URL: http://$RUNNER_HIVEMIND_BENCHMARK_SERVER_HOSTNAME
    RUNNER_HIVEMIND_SMOKETEST_URL: http://$RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME
    AWAIT_SERVICE_ACCESS_TOKEN: $AWAIT_ACCESS_TOKEN
    AWAIT_PACKAGE_URL: $CI_SERVER_URL/api/v4/projects/345/packages/generic/await/v1.3.2/await
    LOG_SERVER_PORT: 8090
  before_script:
    - |
      pip install --no-cache-dir --verbose --user tox==3.25.0
      export PATH=/home/hivemind/.local/bin:$PATH
  script:
    - |
      echo "HAF image name $HAF_IMAGE_NAME"
      echo "Hivemind image name $HIVEMIND_IMAGE"
      wget --header "PRIVATE-TOKEN: $AWAIT_ACCESS_TOKEN" "$AWAIT_PACKAGE_URL"
      chmod +x await
      echo "Waiting for Hivemind sync to complete on ${RUNNER_HIVEMIND_SYNC_URL}"
      ./await -t 1h ${RUNNER_HIVEMIND_SYNC_URL} -- echo "Hivemind sync has finished running"
      SMOKETEST_AWAIT_URL="tcp://${RUNNER_HIVEMIND_SMOKETEST_SERVER_HOSTNAME}:${RUNNER_HIVEMIND_SERVER_HTTP_PORT}"
      echo "Waiting for Hivemind smoketest server to start running on ${SMOKETEST_AWAIT_URL}"
      ./await -t 10m "${SMOKETEST_AWAIT_URL}" -- echo "Hivemind smoketest instance is running"
    - *bridge_api_smoketest-script
    - *bridge_api_smoketest_negative-script
    - *condenser_api_smoketest-script
    - *condenser_api_smoketest_negative-script
    - *database_api_smoketest-script
    - *database_api_smoketest_negative-script
    - *follow_api_smoketest-script
    - *follow_api_smoketest_negative-script
    - *tags_api_smoketest-script
    - *tags_api_smoketest_negative-script
    - *mock_tests-script
    - *hive_api_smoketest-script
    - |
      BENCHMARK_AWAIT_URL="tcp://${RUNNER_HIVEMIND_BENCHMARK_SERVER_HOSTNAME}:${RUNNER_HIVEMIND_SERVER_HTTP_PORT}"
      echo "Waiting for Hivemind benchmark server to start running on ${BENCHMARK_AWAIT_URL}"
      ./await -t 10m "${BENCHMARK_AWAIT_URL}" -- echo "Hivemind benchmark instance is running"
    - *api-benchmark-script
  after_script:
    - |
      echo "Downloading logs..."
      wget ${RUNNER_HIVEMIND_SYNC_URL}/hivemind-sync.log || true
      wget ${RUNNER_HIVEMIND_SYNC_URL}/version.log || true
      mkdir pg-stats
      wget ${RUNNER_HIVEMIND_SYNC_URL}/pg-stats/pg_settings.csv -O pg-stats/pg_settings.csv || true
      wget ${RUNNER_HIVEMIND_SYNC_URL}/pg-stats/pg_stat_user_tables.csv -O pg-stats/pg_stat_user_tables.csv.csv || true
      wget $RUNNER_HIVEMIND_SMOKETEST_URL:$LOG_SERVER_PORT/request_process_times_smoketests.log || true
      wget $RUNNER_HIVEMIND_SMOKETEST_URL:$LOG_SERVER_PORT/hivemind-server.log || true
      wget $RUNNER_HIVEMIND_BENCHMARK_URL:$LOG_SERVER_PORT/request_process_times.log || true
      wget $RUNNER_HIVEMIND_BENCHMARK_URL:$LOG_SERVER_PORT/hivemind-benchmark-server.log || true
    - |
      echo "Preparing dotenv file..."
      {
        echo "ARTIFACTS_JOB_ID=$CI_JOB_ID"
        echo "APP_VERSION=$(python -c "with open('version.log') as f:  exec(f.read()); print(__version__)")"
        echo "SERVER_NAME=$CI_RUNNER_DESCRIPTION"
      } > variables.env
      cat variables.env
  artifacts:
    when: always
    expire_in: 7 days
    reports:
      junit: "*.xml"
      dotenv: variables.env
    paths:
      - hivemind-sync.log
      - hivemind-server.log
      - hivemind-benchmark-server.log
      - pg-stats
      - tests/api_tests/hivemind/tavern/**/*.out.json
      - request_process_times.log
      - request_process_times_smoketests.log
      - version.log
  tags:
    - hive-builder-4

publish_instance_image:
  stage: publish
  extends: .publish_docker_image_template
  script:
    - |
      TAG=$(echo "$CI_COMMIT_TAG" | sed 's/[!+]/-/g')
      scripts/ci-helpers/build_and_publish_instance.sh --image-tag=$TAG
  tags: *shared_tags

Trigger benchmark-results-collector:
  stage: collector
  needs: [ 'sync_e2e_benchmark' ]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "develop"'
      when: on_success
    - when: manual
  variables:
    ARTIFACTS_URL: https://gitlab.syncad.com/api/v4/projects/$CI_PROJECT_ID/jobs/$ARTIFACTS_JOB_ID/artifacts
    PRIVATE_TOKEN: $READ_ARTIFACT_ACCESS_TOKEN
    #description:
    SOURCE: hivemind
    JOB_ID: $ARTIFACTS_JOB_ID
    DESC: "hivemind CI"
    EXEC_ENV_DESC: "branch=$CI_COMMIT_REF_SLUG"
    SERVER_NAME: "$SERVER_NAME"
    APP_VERSION: "$APP_VERSION"
    TESTSUITE_VERSION: "commit_short_sha=$CI_COMMIT_SHORT_SHA"
  trigger:
    project: hive/benchmark-results-collector
    branch: master
    strategy: depend

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| JOBS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
