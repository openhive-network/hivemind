stages:
  - build
  - sync-e2e-benchmark
  - publish
  - collector
  - cleanup

variables:
  # HIVEMIND
  RUNNER_HIVEMIND_SERVER_HTTP_PORT: 8080
  # HAF
  HAF_POSTGRES_URL: postgresql://haf_app_admin@haf-instance:5432/haf_block_log
  HAF_ADMIN_POSTGRES_URL: postgresql://haf_admin@haf-instance:5432/haf_block_log
  # FF:
  FF_NETWORK_PER_BUILD: 1
  # GIT:
  GIT_DEPTH: 1
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: recursive
  CI_DEBUG_SERVICES: "true"
  DATA_CACHE_MAINNET: /cache/replay_data_hivemind_${CI_PIPELINE_ID}
  BLOCK_LOG_SOURCE_DIR_5M: /blockchain/block_log_5m

include:
  - project: hive/haf
    ref: d533a7afbba53ecc7bb1030dbfa6c181bb899409 # develop 
    file: /scripts/ci-helpers/prepare_data_image_job.yml

workflow:
  # do not create pipeline twice when merge requests is open on current branch
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_MERGE_REQUEST_ID'
    - if: '$CI_OPEN_MERGE_REQUESTS'
      when: never
    - when: always

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| ANCHORS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.shared_tags:
  tags: &shared_tags
    - public-runner-docker
    - hived-for-tests

.start-timer: &start-timer
  - ./scripts/ci/timer.sh start

.check-timer: &check-timer
  - ./scripts/ci/timer.sh check

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| ANCHORS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| BASH SCRIPTS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

.instance-build-script: &instance-build-script
  - |
    ./scripts/ci-helpers/build_instance.sh \
      "$CI_COMMIT_SHA" \
      "$CI_PROJECT_DIR" \
      "$CI_REGISTRY_IMAGE" \
      --dot-env-filename=hivemind_image.env \
      --dot-env-var-name=HIVEMIND_IMAGE
    docker images
    docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"
    source hivemind_image.env
    docker push "$HIVEMIND_IMAGE"  

.bridge_api_smoketest-script: &bridge_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_patterns/ \
        api_smoketest_bridge.xml \
        $RUNNER_PYTEST_WORKERS

.bridge_api_smoketest_negative-script: &bridge_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        bridge_api_negative/ \
        api_smoketest_bridge_negative.xml \
        $RUNNER_PYTEST_WORKERS

.condenser_api_smoketest-script: &condenser_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_patterns/ \
        api_smoketest_condenser_api.xml \
        $RUNNER_PYTEST_WORKERS

.condenser_api_smoketest_negative-script: &condenser_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        condenser_api_negative/ \
        api_smoketest_condenser_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.database_api_smoketest-script: &database_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_patterns/ \
        api_smoketest_database_api.xml \
        $RUNNER_PYTEST_WORKERS

.database_api_smoketest_negative-script: &database_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        database_api_negative/ \
        api_smoketest_database_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.follow_api_smoketest-script: &follow_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_patterns/ \
        api_smoketest_follow_api.xml \
        $RUNNER_PYTEST_WORKERS

.follow_api_smoketest_negative-script: &follow_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        follow_api_negative/ \
        api_smoketest_follow_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.tags_api_smoketest-script: &tags_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_negative/ \
        api_smoketest_tags_api_negative.xml \
        $RUNNER_PYTEST_WORKERS

.tags_api_smoketest_negative-script: &tags_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        tags_api_patterns/ \
        api_smoketest_tags_api.xml \
        $RUNNER_PYTEST_WORKERS

.mock_tests-script: &mock_tests-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        mock_tests/ \
        api_smoketest_mock_tests.xml \
        $RUNNER_PYTEST_WORKERS

.hive_api_smoketest-script: &hive_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        hive_api_patterns/ \
        api_smoketest_hive_api.xml \
        $RUNNER_PYTEST_WORKERS

.api-benchmark-script: &api-benchmark-script
  - |
    ./scripts/ci/start-api-benchmarks.sh \
        localhost \
        $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        $RUNNER_BENCHMARK_ITERATIONS \
        $RUNNER_PYTEST_WORKERS 

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| BASH SCRIPTS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>| JOBS |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

prepare_haf_image:
  stage: build
  extends: .prepare_haf_image
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    REGISTRY_USER: "$HAF_IMG_BUILDER_USER"
    REGISTRY_PASS: "$HAF_IMG_BUILDER_PASSWORD"
  before_script:
    - git config --global --add safe.directory $CI_PROJECT_DIR/haf
  tags: *shared_tags

prepare_haf_data:
  extends: .prepare_haf_data_5m
  needs:
    - job: prepare_haf_image
      artifacts: true
  stage: build
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    BLOCK_LOG_SOURCE_DIR: $BLOCK_LOG_SOURCE_DIR_5M
    CONFIG_INI_SOURCE: "$CI_PROJECT_DIR/haf/docker/config_5M.ini"
  tags:
    - hive-builder-4

prepare_hivemind_image:
  stage: build
  extends: .docker_image_builder_job_template
  before_script:
    - git config --global --add safe.directory $CI_PROJECT_DIR
  script:
    - *instance-build-script
  artifacts:
    when: always
    expire_in: 7 days
    reports:
      dotenv: hivemind_image.env
    paths:
      - hivemind_image.env
  tags: *shared_tags

cleanup_haf_cache_manual:
  extends: .cleanup_cache_manual
  stage: cleanup
  variables:
    CLEANUP_PATH_PATTERN: "/cache/replay_data_hivemind_*"
  resource_group: ${CI_COMMIT_SHA}
  tags:
    - hive-builder-4

sync_e2e_benchmark:
  image: $CI_REGISTRY_IMAGE/ci_base_image:3.8
  stage: sync-e2e-benchmark
  needs:
    - job: prepare_haf_data
      artifacts: true
  when: on_success
  services:
    - name: $HAF_IMAGE_NAME
      alias: haf-instance
      variables:
        PG_ACCESS: "
         host    haf_block_log    haf_app_admin    0.0.0.0/0    trust\n
         host    haf_block_log    haf_admin        0.0.0.0/0    trust\n
         "
        DATADIR: $DATA_CACHE_MAINNET/datadir
        SHM_DIR: $DATA_CACHE_MAINNET/shm_dir
        LOG_FILE: $CI_JOB_NAME.log
      command: ["--replay-blockchain", "--stop-replay-at-block=5000000"]
  variables:
    RUNNER_HIVEMIND_SYNC_MAX_BLOCK: 5000024
    HIVED_UID: $HIVED_UID
  before_script:
    - scripts/ci/fix_ci_tag.sh
    - python3 -V
    - pip3 -V
    - python3 -m venv venv/
    - . venv/bin/activate
    - pip install --upgrade pip setuptools wheel
    - pip install --no-cache-dir .[tests] 2>&1 | tee pip_install.log
    - pip list
    - env
  script:
    - echo "HAF image name $HAF_IMAGE_NAME"
    - ./scripts/ci/wait-for-postgres.sh $HAF_ADMIN_POSTGRES_URL
    - ./scripts/ci/add-mocks-to-db.sh
    - psql "${HAF_ADMIN_POSTGRES_URL}" -c 'CREATE EXTENSION IF NOT EXISTS intarray;'
    - ./scripts/ci/hive-sync.sh
    - ./scripts/ci/collect-db-stats.sh
    - ./scripts/ci/hive-server.sh start
    - *bridge_api_smoketest-script
    - *bridge_api_smoketest_negative-script
    - *condenser_api_smoketest-script
    - *condenser_api_smoketest_negative-script
    - *database_api_smoketest-script
    - *database_api_smoketest_negative-script
    - *follow_api_smoketest-script
    - *follow_api_smoketest_negative-script
    - *tags_api_smoketest-script
    - *tags_api_smoketest_negative-script
    - *mock_tests-script
    - *hive_api_smoketest-script
    - ./scripts/ci/hive-server.sh stop
    - mv ./request_process_times.log ./request_process_times_smoketests.log
    - ./scripts/ci/hive-server.sh start
    - *api-benchmark-script
  after_script:
    - cat venv/lib/python3.8/site-packages/hive/_version.py > version.log
    - echo "ARTIFACTS_JOB_ID=$CI_JOB_ID" >> variables.env
    - echo "APP_VERSION=$(git describe --tags)" >> variables.env
    - echo "SERVER_NAME=$CI_RUNNER_DESCRIPTION" >> variables.env
  artifacts:
    when: always
    expire_in: 7 days
    reports:
      junit: "*.xml"
      dotenv: variables.env
    paths:
      - pip_install.log
      - hivemind-sync.log
      - hivemind-server.log
      - pg-stats
      - tests/api_tests/hivemind/tavern/**/*.out.json
      - request_process_times.log
      - request_process_times_smoketests.log
      - version.log
  tags:
    - hive-builder-4

publish_instance_image:
  stage: publish
  extends: .publish_docker_image_template
  script:
    - |
      TAG=$(echo "$CI_COMMIT_TAG" | sed 's/[!+]/-/g')
      scripts/ci-helpers/build_and_publish_instance.sh --image-tag=$TAG
  tags: *shared_tags

Trigger benchmark-results-collector:
  stage: collector
  needs: [ 'sync_e2e_benchmark' ]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "develop"'
      when: on_success
    - when: manual
  variables:
    ARTIFACTS_URL: https://gitlab.syncad.com/api/v4/projects/$CI_PROJECT_ID/jobs/$ARTIFACTS_JOB_ID/artifacts
    PRIVATE_TOKEN: $READ_ARTIFACT_ACCESS_TOKEN
    #description:
    SOURCE: hivemind
    JOB_ID: $ARTIFACTS_JOB_ID
    DESC: "hivemind CI"
    EXEC_ENV_DESC: "branch=$CI_COMMIT_REF_SLUG"
    SERVER_NAME: "$SERVER_NAME"
    APP_VERSION: "$APP_VERSION"
    TESTSUITE_VERSION: "commit_short_sha=$CI_COMMIT_SHORT_SHA"
  trigger:
    project: hive/benchmark-results-collector
    branch: master
    strategy: depend

#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<| JOBS |<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
