stages:
  - build
  - sync-e2e-benchmark
  - data-supply
  - deploy
  - e2e-test
  - benchmark-tests
  - post-deploy

variables:
  GIT_DEPTH: 1
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: recursive
  HAF_POSTGRES_URL: postgresql://haf_app_admin@haf-instance:5432/haf_block_log

.start-timer: &start-timer
  - ./scripts/ci/timer.sh start

.stop-timer: &stop-timer
  - ./scripts/ci/timer.sh check

.rules-for-sync: &rules-for-sync
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: always
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always
    - if: '$CI_COMMIT_BRANCH == "develop"'
      when: always
    - if: '$CI_PIPELINE_SOURCE == "push"'
      when: manual
    - when: manual

include:
  - project: 'hive/haf'
    ref: develop
    file: '/scripts/ci-helpers/prepare_data_image_job.yml'

##### Jobs #####

prepare_haf_image:
  extends: .prepare_haf_data_5m_image
  <<: *rules-for-sync
  stage: build

  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    REGISTRY_USER: "$HAF_IMG_BUILDER_USER"
    REGISTRY_PASS: $HAF_IMG_BUILDER_PASSWORD

  tags:
    - public-runner-docker
    - hived-for-tests

.bridge_api_smoketest-script: &bridge_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        bridge_api_patterns/ api_smoketest_bridge.xml \
        $RUNNER_TEST_JOBS


.bridge_api_smoketest_negative-script: &bridge_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        bridge_api_negative/ api_smoketest_bridge_negative.xml \
        $RUNNER_TEST_JOBS

.condenser_api_smoketest-script: &condenser_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        condenser_api_patterns/ api_smoketest_condenser_api.xml \
        $RUNNER_TEST_JOBS

.condenser_api_smoketest_negative-script: &condenser_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        condenser_api_negative/ api_smoketest_condenser_api_negative.xml \
        $RUNNER_TEST_JOBS

.database_api_smoketest-script: &database_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        database_api_patterns/ api_smoketest_database_api.xml \
        $RUNNER_TEST_JOBS

.database_api_smoketest_negative-script: &database_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        database_api_negative/ api_smoketest_database_api_negative.xml \
        $RUNNER_TEST_JOBS

.follow_api_smoketest-script: &follow_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        follow_api_patterns/ api_smoketest_follow_api.xml \
        $RUNNER_TEST_JOBS

.follow_api_smoketest_negative-script: &follow_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        follow_api_negative/ api_smoketest_follow_api_negative.xml \
        $RUNNER_TEST_JOBS

.tags_api_smoketest-script: &tags_api_smoketest-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        tags_api_negative/ api_smoketest_tags_api_negative.xml \
        $RUNNER_TEST_JOBS

.tags_api_smoketest_negative-script: &tags_api_smoketest_negative-script
  - |
    ./scripts/ci/start-api-smoketest.sh \
        localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
        tags_api_patterns/ api_smoketest_tags_api.xml \
        $RUNNER_TEST_JOBS

.mock_tests-script: &mock_tests-script
  - |
    scripts/ci/start-api-smoketest.sh \
    localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
    mock_tests/ api_smoketest_mock_tests.xml \
    $RUNNER_TEST_JOBS

.hive_api_smoketest-script: &hive_api_smoketest-script
  - |
    scripts/ci/start-api-smoketest.sh \
    localhost "$RUNNER_HIVEMIND_SERVER_HTTP_PORT" \
    hive_api_patterns/ api_smoketest_hive_api.xml \
    $RUNNER_TEST_JOBS

.api-benchmark-script: &api-benchmark-script
  - |
    ./scripts/ci/start-api-benchmarks.sh \
        localhost $RUNNER_HIVEMIND_SERVER_HTTP_PORT \
        $RUNNER_BENCHMARK_ITERATIONS \
        $RUNNER_BENCHMARK_JOBS \
        $CI_PROJECT_DIR/tests/api_tests/hivemind/tavern

sync-e2e-benchmark:
#  extends: .docker_image_builder_job
  <<: *rules-for-sync
  stage: sync-e2e-benchmark

  variables:
    PIPENV_VENV_IN_PROJECT: 1
    PIPENV_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pipenv"
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
    POSTGRES_CLIENT_TOOLS_PATH: /usr/lib/postgresql
    HIVEMIND_DB_NAME: "hive_${CI_COMMIT_REF_SLUG}"
    HAF_POSTGRES_URL: postgresql://haf_app_admin@haf-instance:5432/haf_block_log
    HAF_ADMIN_POSTGRES_URL: postgresql://haf_admin@haf-instance:5432/haf_block_log
    RUNNER_POSTGRES_ADMIN_USER: "haf_app_admin"
    RUNNER_POSTGRES_HOST: "haf-instance"
    RUNNER_POSTGRES_PORT: 5432
    FF_NETWORK_PER_BUILD: 1

  needs:
    - job: prepare_haf_image
      artifacts: true

  services:
    - name: $HAF_IMAGE_NAME
      alias: haf-instance

  before_script:
#    - !reference [.docker_image_builder_job, before_script] 
    - apk update && apk add bash git ca-certificates curl build-base python3-dev postgresql-client
    - python3 -m ensurepip
    - pip3 install tox

  script:
    - echo "HAF image name $HAF_IMAGE_NAME"
    - ./scripts/ci/wait-for-postgres.sh "haf-instance"
    # temporary soln just to get things working
    # - docker logout || true
    # - docker info
    # - docker context list
    # - docker ps
    # - docker network ls
    # - echo $HIVEMIND_CI_IMGBUILDER_PASSWORD | docker login -u "$HIVEMIND_CI_IMG_BUILDER_USER" registry.gitlab.syncad.com/hive/hivemind --password-stdin
    # - echo "Login succeeded - continuing execution"
    # - docker container exec -it haf-instance /bin/bash -c "psql -d haf_block_log -c 'CREATE EXTENSION IF NOT EXISTS intarray;'"
    - psql -d ${HAF_ADMIN_POSTGRES_URL} -c 'CREATE EXTENSION IF NOT EXISTS intarray;'
    - export RUNNER_HIVEMIND_LAST_BLOCK_FOR_MASSIVE=4999979
    - export RUNNER_HIVED_DB_URL=${HAF_POSTGRES_URL}
    - ./scripts/ci/hive-sync.sh
    - ./scripts/ci/collect-db-stats.sh
    - ./scripts/ci/hive-server.sh start
    - pip install tox
    - touch tox-installed
    - *bridge_api_smoketest-script
    - *bridge_api_smoketest_negative-script
    - *condenser_api_smoketest-script
    - *condenser_api_smoketest_negative-script
    - *database_api_smoketest-script
    - *database_api_smoketest_negative-script
    - *follow_api_smoketest-script
    - *follow_api_smoketest_negative-script
    - *tags_api_smoketest-script
    - *tags_api_smoketest_negative-script
    - *mock_tests-script
    - *hive_api_smoketest-script
    - ./scripts/ci/hive-server.sh stop
    - mv ./request_process_times.log ./request_process_times_smoketests.log
    - ./scripts/ci/hive-server.sh start
    - *api-benchmark-script
  after_script:
    - echo "ARTIFACTS_JOB_ID=$CI_JOB_ID" >> variables.env
    - echo "APP_VERSION=$(git describe --tags)" >> variables.env
    - echo "SERVER_NAME=$CI_RUNNER_DESCRIPTION" >> variables.env
  artifacts:
    when: always
    paths:
      - hivemind-sync.log
      - hivemind-server.log
      - pg-stats
      - hive-sync-runner-id.txt
      - tavern_benchmarks_report.html
      - tests/api_tests/hivemind/tavern/**/*.out.json
      - request_process_times.log
      - request_process_times_smoketests.log
    reports:
      junit: "*.xml"
      dotenv: variables.env
    expire_in: 7 days
  tags:
    - public-runner-docker
    - hived-for-tests

Trigger benchmark-results-collector:
  stage: post-deploy
  needs: ["sync-e2e-benchmark"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "develop"'
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "push"'
      when: manual
    - when: manual
  variables:
    ARTIFACTS_URL: https://gitlab.syncad.com/api/v4/projects/$CI_PROJECT_ID/jobs/$ARTIFACTS_JOB_ID/artifacts
    PRIVATE_TOKEN: $READ_ARTIFACT_ACCESS_TOKEN
    #description:
    SOURCE: hivemind
    JOB_ID: $ARTIFACTS_JOB_ID
    DESC: "hivemind CI"
    EXEC_ENV_DESC: branch=$CI_COMMIT_REF_SLUG
    SERVER_NAME: $SERVER_NAME
    APP_VERSION: $APP_VERSION
    TESTSUITE_VERSION: commit_short_sha=$CI_COMMIT_SHORT_SHA
  trigger:
    project: hive/benchmark-results-collector
    branch: mzebrak/haf-compatible-hivemind
    strategy: depend